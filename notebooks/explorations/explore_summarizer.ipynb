{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import summarize, keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "Gensim summarizer only extracts important sentence from source text,\n",
    "and seems to rank those sentences based on their scores, and return as results.\n",
    "So, it is not suitable for multi-document summarization, since there is no correlation or coherence\n",
    "between documents(tweets, reddits, etc.)\n",
    "And for abstractive summarization, I think the summary will result in same problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Long Text\n",
    "\n",
    "Summarizer only makes sense when summarizing single document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \\\n",
    "\"\"\"Photographic style transfer is a long-standing problem that seeks to transfer the style of a reference style photo onto another input picture.\n",
    "For instance, by appropriately choosing the reference style photo, one can make the input picture look like it has been taken under a different illumination, time of day, or weather, or that it has been artistically retouched with a different intent.\n",
    "So far, existing techniques are either limited in the diversity of scenes or transfers that they can handle or in the faithfulness of the stylistic match they achieve.\n",
    "In this paper, we introduce a deep-learning approach to photographic style transfer that is at the same\n",
    "time broad and faithful, i.e., it handles a large variety of\n",
    "image content while accurately transferring the reference\n",
    "style. Our approach builds upon the recent work on Neural\n",
    "Style transfer by Gatys et al. [5]. However, as shown in\n",
    "Figure 1, even when the input and reference style images\n",
    "are photographs, the output still looks like a painting, e.g.,\n",
    "straight edges become wiggly and regular textures wavy.\n",
    "One of our contributions is to remove these painting-like effects by preventing spatial distortion and constraining the\n",
    "transfer operation to happen only in color space. We achieve\n",
    "this goal with a transformation model that is locally affine in\n",
    "colorspace, which we express as a custom fully differentiable\n",
    "energy term inspired by the Matting Laplacian [9]. We show\n",
    "that this approach successfully suppresses distortion while\n",
    "having a minimal impact on the transfer faithfulness. Our\n",
    "other key contribution is a solution to the challenge posed\n",
    "by the difference in content between the input and reference\n",
    "images, which could result in undesirable transfers between\n",
    "unrelated content. For example, consider an image with less\n",
    "sky visible in the input image; a transfer that ignores the\n",
    "difference in context between style and input may cause the\n",
    "style of the sky to “spill over” the rest of the picture. We\n",
    "show how to address this issue using semantic segmentation\n",
    "[3] of the input and reference images. We demonstrate\n",
    "the effectiveness of our approach with satisfying photorealistic\n",
    "style transfers for a broad variety of scenarios including\n",
    "transfer of the time of day, weather, season, and artistic edits.\n",
    "From a practical perspective, our contribution is an effective\n",
    "algorithm for photographic style transfer suitable\n",
    "for many applications such as altering the time of day or\n",
    "weather of a picture, or transferring artistic edits from a\n",
    "photo to another. To achieve this result, we had to address\n",
    "two fundamental challenges.\n",
    "There is an inherent tension in\n",
    "our objectives. On the one hand, we aim to achieve very\n",
    "local drastic effects, e.g., to turn on the lights on individual\n",
    "skyscraper windows (Fig. 1). On the other hand, these effects\n",
    "should not distort edges and regular patterns, e.g., so that the\n",
    "windows remain aligned on a grid. Formally, we seek a transformation\n",
    "that can strongly affect image colors while having\n",
    "no geometric effect, i.e., nothing moves or distorts. Reinhard\n",
    "et al. [12] originally addressed this challenge with a global\n",
    "color transform. However, by definition, such a transform\n",
    "cannot model spatially varying effects and thus is limited\n",
    "in its ability to match the desired style. More expressivity\n",
    "requires spatially varying effects, further adding to the challenge\n",
    "of preventing spatial distortion. A few techniques exist\n",
    "for specific scenarios [8, 15] but the general case remains\n",
    "unaddressed. Our work directly takes on this challenge and\n",
    "provides a first solution to restricting the solution space to\n",
    "photorealistic images, thereby touching on the fundamental\n",
    "task of differentiating photos from paintings.\n",
    "Semantic accuracy and transfer faithfulness. The complexity\n",
    "of real-world scenes raises another challenge: the\n",
    "transfer should respect the semantics of the scene. For instance,\n",
    "in a cityscape, the appearance of buildings should be\n",
    "matched to buildings, and sky to sky; it is not acceptable to make the sky look like a building. One plausible approach is\n",
    "to match each input neural patch with the most similar patch\n",
    "in the style image to minimize the chances of an inaccurate\n",
    "transfer. This strategy is essentially the one employed by\n",
    "the CNNMRF method [10]. While plausible, we find that it\n",
    "often leads to results where many input patches get paired\n",
    "with the same style patch, and/or that entire regions of the\n",
    "style image are ignored, which generates outputs that poorly\n",
    "match the desired style.\n",
    "One solution to this problem is to transfer the complete\n",
    "“style distribution” of the reference style photo as captured\n",
    "by the Gram matrix of the neural responses [5]. This approach\n",
    "successfully prevents any region from being ignored.\n",
    "However, there may be some scene elements more (or less)\n",
    "represented in the input than in the reference image. In such\n",
    "cases, the style of the large elements in the reference style\n",
    "image “spills over” into mismatching elements of the input\n",
    "image, generating artifacts like building texture in the sky. A\n",
    "contribution of our work is to incorporate a semantic labeling\n",
    "of the input and style images into the transfer procedure so\n",
    "that the transfer happens between semantically equivalent\n",
    "subregions and within each of them, the mapping is close\n",
    "to uniform. As we shall see, this algorithm preserves the\n",
    "richness of the desired style and prevents spillovers. These\n",
    "issues are demonstrated in Figure 2.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text = text.replace('\\n', ' ')\n",
    "text = re.sub(r'\\s+', ' ', text)\n",
    "text = text.strip()\n",
    "text = ' '.join([sent.text for sent in nlp(text).sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The domestic dog (Canis lupus familiaris or Canis familiaris) is a member of genus Canis (canines) that forms part of the wolf-like canids, and is the most widely abundant carnivore.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(wikipedia.summary(\"dog\"), ratio=0.2, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transferring', array([ 0.34156552])),\n",
       " ('style', array([ 0.28404195])),\n",
       " ('image', array([ 0.23064807])),\n",
       " ('semantics', array([ 0.16740352])),\n",
       " ('effective', array([ 0.14613938])),\n",
       " ('spatially', array([ 0.14069739])),\n",
       " ('like', array([ 0.13472327]))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(text, ratio=0.05, split=True, scores=True, lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize tweets in the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading SpaCy \"en_core_web_md\" corpus...\n",
      "* Success.\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "* Parsing texts...\n",
      "* Cleaning texts...\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "* Transforming texts to feature vectors...\n",
      "* Clustering...\n",
      "* Done.\n",
      "--------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../data_helpers/')\n",
    "sys.path.append('../cluster/')\n",
    "\n",
    "from twitter_data_helper import TwitterDataHelper\n",
    "from cluster import Cluster\n",
    "\n",
    "data_helper = TwitterDataHelper()\n",
    "df = data_helper.get_data(['2017-07-17', '2017-07-18', '2017-07-19'])\n",
    "\n",
    "cluster = Cluster()\n",
    "\n",
    "df = cluster.cluster(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.best_cluster_model.n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '\\n'.join([text for text in df[df['cluster'] == 2].text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What did we learn and what happens next from the Securing Agile Delivery track at CyberUK?',\n",
       " \"Find out why #machinelearning and #AI are the future of #cybersecurity at Andrew Gardner's #BHUSA talk next week: https://t.co/cCxsWwJSOT\",\n",
       " 'Naked Security | Wait, you didn’t want to clean the toilets?',\n",
       " 'Help shape the future of #AI &amp; virtual assistants with a #Cortana research internship… https://t.co/B3MVxQGhMQ',\n",
       " 'I‘m a city boy…So, I was surprised to learn cowboys are using smart watches and wearables to track their cows:… https://t.co/oThyp7MPBL',\n",
       " \"I opened a VM saved in April (so shouldn't full updated), disable the network, check Office update, guess what I go… https://t.co/PtrojBdmfX\",\n",
       " \"Hmm, while looking at @scriptjunkie1's Office update issue https://t.co/5fmWl7baFe, I think I found another shitty one..\",\n",
       " \"I should clarify: Tesla stock is obviously high based on past &amp; present, but low if you believe in Tesla's future.… https://t.co/XzG3z7jo0A\",\n",
       " 'When I do cyber security this is the soundtrack I think is playing.',\n",
       " 'Seems TeslaWare guy thought with deleting Twitter account, changing name, and using a joke TOS will protect him...… https://t.co/btoc9Uwyod',\n",
       " 'An end to end implementation of a Machine Learning pipeline: A great tutorial with Jupyter notebook for ML beginner… https://t.co/UEGQ43Qd04',\n",
       " \"My quick write-up on the limitations of deep learning: https://t.co/9upBSqsOOb It's meant as an intro to tomorrow's post on the future of DL\",\n",
       " \"Some of my thoughts on the future of deep learning: https://t.co/PweWuM1C8h - This is the follow-up to yesterday's post on the limits of DL.\",\n",
       " 'If you cite the number of firewall drops as a number of cyber attacks, you are a bad person.',\n",
       " \"Then: I met with Russian agents, but the Secret Service didn't stop it… https://t.co/XLhfrQbYky\",\n",
       " 'You keep doing good infosec, but then admins turn off the host firewall and put people in local admin group - destr… https://t.co/TpIRfRIosV',\n",
       " 'That said: I updated my user script to apply a few changes I find useful to the new interface.',\n",
       " 'For all of those, who are less fortunate than I am: I am giving away 4 Cyber Security Humble Bundles: https://t.co/kC5jhJRaQp',\n",
       " '[P] Noise in Design Using machine Learning, style transfer, and cellular automaton to explore the role of noise in… https://t.co/z2AWHvK3FX']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Apparently, it just ranks the important tweets and return the results. \"\"\"\n",
    "\n",
    "summarize(text, ratio=0.1, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https', array([ 0.82361567])),\n",
       " ('security', array([ 0.16643479])),\n",
       " ('new', array([ 0.12400706])),\n",
       " ('network', array([ 0.08043786])),\n",
       " ('registered', array([ 0.07908443]))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(text, ratio=0.005, split=True, scores=True, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Ignore here, just for debugging interest of rows \"\"\"\n",
    "debug_idxs = []\n",
    "for i, text in enumerate(df.text):\n",
    "    if 'Clustering' in text.split(): debug_idxs.append(i)\n",
    "\n",
    "df.loc[debug_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to summarize text extracted from URL\n",
    "\n",
    "### Test source: [Your tl;dr by an ai: a deep reinforced model for abstractive summarization](https://einstein.ai/research/your-tldr-by-an-ai-a-deep-reinforced-model-for-abstractive-summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://einstein.ai/research/your-tldr-by-an-ai-a-deep-reinforced-model-for-abstractive-summarization'\n",
    "article = Article(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salesforce Research'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your tl;dr by an ai: a deep reinforced model for abstractive summarization\\n\\nThe last few decades have witnessed a fundamental change in the challenge of taking in new information. The bottleneck is no longer access to information; now it’s our ability to keep up. We all have to read more and more to keep up-to-date with our jobs, the news, and social media. We’ve looked at how AI can improve people’s work by helping with this information deluge and one potential answer is to have algorithms automatically summarize longer texts.\\n\\nTraining a model that can generate long, coherent, and meaningful summaries remains an open research problem. In fact, generating any kind of longer text is hard for even the most advanced deep learning algorithms. In order to make summarization successful, we introduce two separate improvements: a more contextual word generation model and a new way of training summarization models via reinforcement learning (RL).\\n\\nThe combination of the two training methods enables the system to create relevant and highly readable multi-sentence summaries of long text, such as news articles, significantly improving on previous results. Our algorithm can be trained on a variety of different types of texts and summary lengths. In this blog post, we present the main contributions of our model and an overview of the natural language challenges specific to text summarization.\\n\\nExtractive vs. Abstractive Summarization\\n\\nAutomatic summarization models can work in one of two ways: by extraction or by abstraction. Extractive models perform \"copy-and-paste\" operations: they select relevant phrases of the input document and concatenate them to form a summary. They are quite robust since they use existing natural-language phrases that are taken straight from the input, but they lack in flexibility since they cannot use novel words or connectors. They also cannot paraphrase like people sometimes do. In contrast, abstractive models generate a summary based on the actual “abstracted” content: they can use words that were not in the original input. This gives them a lot more potential to produce fluent and coherent summaries but it is also a much harder problem as you now require the model to generate coherent phrases and connectors.\\n\\nEven though abstractive models are more powerful in theory, it is common for them to make mistakes in practice. Typical mistakes include incoherent, irrelevant or repeated phrases in generated summaries, especially when trying to create long text outputs. They historically lacked a sense of general coherence, flow and readability. In this work, we tackle these issues and design a more robust and coherent abstractive summarization model.\\n\\nIn order to understand our new abstractive model, let’s first define the basic building blocks and then introduce our new training scheme.\\n\\nReading and Generating Text with Encoder-decoder Models\\n\\nRecurrent neural networks (RNNs) are deep learning models that can process sequences (e.g. text) of variable length and compute useful representations (or hidden state) for each phrase. These networks process each element of the sequence (in this case, each word) one by one; for each new input in the sequence, the network outputs a new hidden state as a function of that input and the previous hidden state. In this sense, the hidden state calculated at each word is a function of all the words read up to that point.\\n\\nRNNs can also be used to generate output sequences in a similar fashion. At each step, the RNN hidden state is used to generate a new word that is added to the final output text and fed in as the next input.\\n\\nThe input (reading) and output (generating) RNNs can be combined in a joint model where the the final hidden state of the input RNN is used as the initial hidden state of the output RNN. Combined in this way, the joint model is able to read any text and generate a different text from it. This framework is called an encoder-decoder RNN (or Seq2Seq) and is the basis of our summarization model. In addition, we replace the traditional encoder RNN by a bidirectional encoder, which uses two different RNNs to read the input sequence: one that reads the text from left-to-right (as illustrated in Figure 4) and another that reads from right-to-left. This helps our model to have a better representation of the input context.\\n\\nA new Attention and Decoding Mechanism\\n\\nTo make our model outputs more coherent, we allow the decoder to look back at parts of the input document when generating a new word with a technique called temporal attention. Instead of relying entirely on its own hidden state, the decoder can incorporate contextual information about different parts of the input with an attention function. This attention is then modulated to ensure that the model uses different parts of the input when generating the output text, hence increasing information coverage of the summary.\\n\\nIn addition, to make sure that our model doesn\\'t repeat itself, we also allow it to look back at the previous hidden states from the decoder. In a similar fashion, we define an intra-decoder attention function that can look back at previous hidden states of the decoder RNNs. Finally, the decoder combines the context vector from the temporal attention with the one from the intra-decoder attention to generate the next word in the output summary. Figure 5 illustrates the combination of these two attention functions at a given decoding step.\\n\\nHow to Train this Model? Supervised Learning vs. Reinforcement Learning\\n\\nTo train this model on real-world data like news articles, a common way is to use the teacher forcing algorithm: a model generates a summary while using a reference summary, and the model is assigned a word-by-word error (or “local supervision”, as shown in Figure 6) each time it generates a new word.\\n\\nThis method can be used to train any sequence generation model based on recurrent neural networks, with very decent results. However, for our particular task, summaries don\\'t have to match a reference sequence word by word in order to be correct. As you can imagine, two humans may generate very different summaries of the same news article, sometimes using different styles, words or sentence orders, while still being considered good summaries. The problem with teacher forcing here is that as soon as the first few words are generated, the training is misguided: it sticks strictly to the one officially correct summary and cannot adjust to a potentially correct but different beginning.\\n\\nTaking this into consideration, we can do better than the word-by-word approach of teacher forcing. A different kind of training called reinforcement learning (RL) can be applied here. At first, the RL algorithm lets the model generate its own summary, then it uses an external scorer to compare the generated summary against the ground truth. This scorer then indicates to the model how \"good\" the generated summary was. If the score is high, then the model can update itself to make such summaries more likely to appear in the future. Otherwise, if the score is low, the model will get penalized and change its generation procedure to prevent similar summaries. This reinforced model is very good at increasing the summarization score that evaluates the entire sequence rather than a word-by-word prediction.\\n\\nHow to Evaluate Summarization?\\n\\nWhat exactly is this scorer, and how does it tell if summaries are \"good\"? Since asking a human to manually evaluate millions of summaries is long and impractical at scale, we rely on an automated evaluation metric called ROUGE (Recall-Oriented Understudy for Gisting Evaluation). ROUGE works by comparing matching sub-phrases in the generated summaries against sub-phrases in the ground truth reference summaries, even if they are not perfectly aligned. Different variants of ROUGE (ROUGE-1, ROUGE-2, ROUGE-L) all work in the same fashion but use different sub-sequence lengths.\\n\\nWhile ROUGE scores have a good correlation with human judgment in general, the summaries with the highest ROUGE aren\\'t necessarily the most readable or natural ones. This became an issue when we trained our model to maximize the ROUGE score with reinforcement learning alone. We observed that our models with the highest ROUGE scores also generated barely-readable summaries.\\n\\nTo bring the best of both worlds, our model is trained with teacher forcing and reinforcement learning at the same time, being able to make use of both word-level and whole-summary-level supervision to make it more coherent and readable. In particular, we find that ROUGE-optimized RL helps improve recall (i.e all important information that needs to be summarized is indeed summarized) and word level learning supervision ensures good language flow, making the summary more coherent and readable.\\n\\nUntil recently, the highest ROUGE-1 score for abstractive summarization on the CNN/Daily Mail dataset was 35.46. The combination of our intra-decoder attention RNN model with joint supervised and RL training improves this score to 39.87, and 41.16 with RL only. Figure 9 shows other summarization scores for existing models and ours. Even though our pure RL model has higher ROUGE scores, our supervised+RL model has a higher readability, hence is more relevant for this summarization task. Note that See et al. use a slightly different data format, hence their results are not directly comparable with ours and the others but still give a good reference point.\\n\\nSample Outputs\\n\\nWhat does such a large improvement mean in terms of real summaries? Here we show a couple of multi-sentence summaries based on documents from the development split of the dataset. Our model and its simpler baselines generated these, after training on the CNN/Daily Mail dataset. As you can see, the summaries have significantly improved but there’s still more work needed to make them perfect.\\n\\nArticle Summary (ground truth) Summary (our model) Google Wallet says it has changed its policy when storing users\\' funds as they will now be federally-insured (file photo) For those who use Google Wallet, their money just became safer with federal-level insurance. Google confirmed to Yahoo Finance in a statement that its current policy changed - meaning the company will store the balances for users of the mobile transfer service (similar to PayPal and Venmo) in multiple federally-insured banking institutions. This is good news for people who place large amounts of money in their Wallet Balance because the Federal Deposit Insurance Corporation insures funds for banking institutions up to $250,000. Currently, Google\\'s user agreement says funds are not protected by the FDIC. However, a Google spokesperson told Yahoo Finance that the current policy has changed. (...) Google spokesperson confirmed current policy changed meaning funds will be protected by the federal deposit insurance corporation. As a non-banking institution, Google Wallet, along with competitors PayPal and Venmo, is not legally required to be federally insured. With the new change to its policy, funds in wallet balance are protected if anything were to happen to the company like bankruptcy. Google confirmed to Yahoo Finance in a statement that its current policy changed. The company will store the balances for users of the mobile transfer service (similar to PayPal and Venmo) in multiple federally-insured banking institutions. Google\\'s user agreement says funds are not protected by the federal deposit insurance corporation. Talk about a chain reaction! This is the moment a billiards player performs a complex trick shot by setting up a domino train to pot four balls. Video footage shows a white ball being rolled down a positioned cue. It then bounces off one side of the red-clothed table and hits the first in a long line of dominoes. One by one the small counters fall down, tapping balls into various pockets as they go. First a yellow, then a blue, then a red. Finally, the last domino gently hits an orange ball, causing it to roll down another positioned cue lying on the table. The orb then knocks a green ball into the center pocket. In less than 30 seconds the stunt comes to a close. (...) The clip was uploaded by youtube user honda4ridered. In another upload the skilled billiards player shows viewers how to pocket four balls in a single shot-and for those who miss it there\\'s a slow motion version. Video footage shows a white ball being rolled down a jumper. It then bounces off one side of the red-clothed table and hits the first in a long line of dominoes. One by one the small counters fall down, tapping balls into pockets as they go-first a yellow. It comes to a close. The clip was uploaded by youtube user honda4ridered. Kelly Osbourne didn\\'t always want to grow up to be like her famous mom - but in a letter published in the new book A Letter to My Mom, the TV personality admitted that she is now proud to be Sharon Osbourne\\'s daughter. For author Lisa Erspamer\\'s third collection of tributes, celebrities such as Melissa Rivers, Shania Twain, will.i.am, Christy Turlington Burns, and Kristin Chenoweth all composed messages of love and gratitude to the women who raised them. And the heartwarming epistolary book, which was published last week, has arrived just in time for Mother\\'s Day on May 10. \\'Like all teenage girls I had this ridiculous fear of growing up and becoming just like you,\\' Kelly Osbourne wrote in her letter, republished on Yahoo Parenting. \\'I was so ignorant and adamant about creating my \"own\" identity.\\' Scroll down for video Mini-me: In Lisa Erspamer\\'s new book A Letter to My Mom, Kelly Osbourne (R) wrote a letter to her mother Sharon (L) saying that she\\'s happy to have grown up to be just like her (...) Author Lisa Erspamer invited celebrities and a number of other people to write heartfelt notes to their mothers for her new book a letter to my mom. Stars such as Melissa Rivers, will.i.am, and Christy Turlington participated in the moving project. Kelly didn\\'t always want to grow up to be like her famous mom. Lisa Erspamer\\'s third collection of tributes, celebrities such as Melissa rivers, Shania Twain, will.i.am, Christy Turlington, and Kristin Chenoweth all composed messages of love and gratitude to the women who raised them. Kelly wrote a letter to her mom before Joan\\'s death last year. She has arrived just in time for Mother\\'s Day on May 10.\\n\\nIn order to illustrate the impact of our main contributions on text summarization, Figure 11 shows how the output of our model diverges if we remove intra-attention and RL training.\\n\\nArticle Tony Blair has said he does not want to retire until he is 91 – as he unveiled plans to set up a ‘cadre’ of ex-leaders to advise governments around the world. The defiant 61-year-old former Prime Minister said he had ‘decades’ still in him and joked that he would ‘turn to drink’ if he ever stepped down from his multitude of global roles. He told Newsweek magazine that his latest ambition was to recruit former heads of government to go round the world to advise presidents and prime ministers on how to run their countries. In an interview with the magazine Newsweek Mr Blair said he did not want to retire until he was 91 years old Mr Blair said his latest ambition is to recruit former heads of government to advise presidents and prime ministers on how to run their countries Mr Blair said he himself had been ‘mentored’ by US president Bill Clinton when he took office in 1997. And he said he wanted to build up his organisations, such as his Faith Foundation, so they are ‘capable of changing global policy’. Last night, Tory MPs expressed horror at the prospect of Mr Blair remaining in public life for another 30 years. Andrew Bridgen said: ‘We all know weak Ed Miliband’s called on Tony to give his flailing campaign a boost, but the attention’s clearly gone to his head.’ (...) Summary (ground truth, written by a human) The former Prime Minister claimed he has \\'decades\\' of work left in him. Joked he would \\'turn to drink\\' if he ever stepped down from global roles. Wants to recruit former government heads to advise current leaders. He was \\'mentored\\' by US president Bill Clinton when he started in 1997. Summary (our model) Blair said he did not want to retire until he was 91 years old. 61-year-old former prime minister said he would \\'turn to drink\\' if he ever stepped down from his own. He said he wanted to build up his charity to advise presidents and prime ministers on how to run their countries. Mr Blair says he is to recruit former heads of government to go round the world to advise ministers. He says he wants to emulate ex-Israeli president Shimon Peres. Summary (without intra-attention and reinforcement learning) 61-year-old former prime minister said he did not want to retire until he was 91 years old. He said he wanted to build up his organisations, such as his Faith Foundation. He said he wanted to emulate ex-Israeli president Shimon Peres. Mr Blair said he wanted to emulate ex-Israeli President Shimon Peres. He said he wanted to be seeing someone when he took office in 1997. Mr Blair said he wanted to be seeing someone when he took office in 1997. Mr Blair said he wanted to\\n\\nConclusion\\n\\nOur model significantly improves the state-of-the-art in multi-sentence summary generation, outperforming existing abstractive models and extractive baselines. We believe that our contributions - the intra-decoder attention module and the combined training objective - could improve other sequence generation tasks, especially for long outputs.\\n\\nOur work also touches on the limit of automatic evaluation metrics such as ROUGE, and shows that better metrics are required to evaluate - and optimize - summarization models. An ideal metric will correlate well with human judgment both in terms of summary coherence and readability. When such a metric is used with our reinforced summarization model summaries may improve even further.\\n\\nCitation credit\\n\\nIf you use this blog post in published work, please cite:\\n\\n\\n\\nA Deep Reinforced Model for Abstractive Summarization Romain Paulus, Caiming Xiong, and Richard Socher. 2017.\\n\\nAcknowledgements\\n\\nSpecial thanks to Melvin Gruesbeck for his help with visuals and figures.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize using Newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Extractive vs. Abstractive SummarizationAutomatic summarization models can work in one of two ways: by extraction or by abstraction.',\n",
       " 'In this work, we tackle these issues and design a more robust and coherent abstractive summarization model.',\n",
       " 'Combined in this way, the joint model is able to read any text and generate a different text from it.',\n",
       " 'This framework is called an encoder-decoder RNN (or Seq2Seq) and is the basis of our summarization model.',\n",
       " 'When such a metric is used with our reinforced summarization model summaries may improve even further.']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The newspaper3k's summary looks bad. \"\"\"\n",
    "article.summary.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summarization',\n",
       " 'summary',\n",
       " 'salesforce',\n",
       " 'model',\n",
       " 'summaries',\n",
       " 'input',\n",
       " 'hidden',\n",
       " 'research',\n",
       " 'blair',\n",
       " 'different',\n",
       " 'text',\n",
       " 'models']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In order to make summarization successful, we introduce two separate improvements: a more contextual word generation model and a new way of training summarization models via reinforcement learning (RL).',\n",
       " 'The combination of the two training methods enables the system to create relevant and highly readable multi-sentence summaries of long text, such as news articles, significantly improving on previous results.',\n",
       " 'Recurrent neural networks (RNNs) are deep learning models that can process sequences (e.g. text) of variable length and compute useful representations (or hidden state) for each phrase.',\n",
       " 'At each step, the RNN hidden state is used to generate a new word that is added to the final output text and fed in as the next input.',\n",
       " 'To make our model outputs more coherent, we allow the decoder to look back at parts of the input document when generating a new word with a technique called temporal attention.',\n",
       " 'This attention is then modulated to ensure that the model uses different parts of the input when generating the output text, hence increasing information coverage of the summary.',\n",
       " 'In a similar fashion, we define an intra-decoder attention function that can look back at previous hidden states of the decoder RNNs. Finally, the decoder combines the context vector from the temporal attention with the one from the intra-decoder attention to generate the next word in the output summary.',\n",
       " 'To train this model on real-world data like news articles, a common way is to use the teacher forcing algorithm: a model generates a summary while using a reference summary, and the model is assigned a word-by-word error (or “local supervision”, as shown in Figure 6) each time it generates a new word.',\n",
       " 'To bring the best of both worlds, our model is trained with teacher forcing and reinforcement learning at the same time, being able to make use of both word-level and whole-summary-level supervision to make it more coherent and readable.',\n",
       " 'In particular, we find that ROUGE-optimized RL helps improve recall (i.e all important information that needs to be summarized is indeed summarized) and word level learning supervision ensures good language flow, making the summary more coherent and readable.',\n",
       " 'Google confirmed to Yahoo Finance in a statement that its current policy changed - meaning the company will store the balances for users of the mobile transfer service (similar to PayPal and Venmo) in multiple federally-insured banking institutions.',\n",
       " 'In order to illustrate the impact of our main contributions on text summarization, Figure 11 shows how the output of our model diverges if we remove intra-attention and RL training.',\n",
       " 'Summary (without intra-attention and reinforcement learning) 61-year-old former prime minister said he did not want to retire until he was 91 years old.',\n",
       " 'We believe that our contributions - the intra-decoder attention module and the combined training objective - could improve other sequence generation tasks, especially for long outputs.']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Try using gensim summarizer. It is much better then `newspaper3k` \n",
    "since the results matches ground truths. \n",
    "\"\"\"\n",
    "summarize(article.text, ratio=0.1, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('summary', array([ 0.27793276])),\n",
       " ('models', array([ 0.22582236])),\n",
       " ('different', array([ 0.17744981])),\n",
       " ('generated', array([ 0.15655664])),\n",
       " ('new', array([ 0.15101865])),\n",
       " ('word', array([ 0.13918288])),\n",
       " ('rnns', array([ 0.13767702])),\n",
       " ('abstractive summarization', array([ 0.1325364])),\n",
       " ('training', array([ 0.12755642])),\n",
       " ('balls', array([ 0.11759542])),\n",
       " ('google', array([ 0.11356443])),\n",
       " ('rouge', array([ 0.1115001])),\n",
       " ('decoding', array([ 0.11005754])),\n",
       " ('evaluation', array([ 0.10528888])),\n",
       " ('improve', array([ 0.10460957])),\n",
       " ('attention', array([ 0.10140333])),\n",
       " ('outputs', array([ 0.10027907])),\n",
       " ('sequence', array([ 0.09976675])),\n",
       " ('insured', array([ 0.09962752])),\n",
       " ('information', array([ 0.09446021]))]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" article.keywords is better then gensim's keywords(),\n",
    "    since article.keywords are given by human.\n",
    "\"\"\"\n",
    "keywords(article.text, ratio=0.05, split=True, scores=True, lemmatize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
