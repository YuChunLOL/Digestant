{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import praw\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../data_helpers/')\n",
    "sys.path.append('../preprocess/')\n",
    "\n",
    "from reddit_data_helper import RedditDataHelper\n",
    "from google_data_helper import GoogleDataHelper\n",
    "from data_aggregator import DataAggregator\n",
    "from text_cleaner import TextCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_helper = DataAggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data_helper.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [TextCleaner] Initializing...\n",
      "* [TextCleaner] Loading SpaCy \"en_core_web_md\" corpus...\n",
      "* [TextCleaner] Loading stopwords...\n",
      "--------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tc = TextCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 734.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [TextCleaner] Cleaning text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Wikipedia', 'Neural', 'Networks'],\n",
       " ['Deep',\n",
       "  'learning',\n",
       "  'Wikipedia',\n",
       "  'Deep',\n",
       "  'learning',\n",
       "  'application',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'ANNs',\n",
       "  'learning',\n",
       "  'tasks',\n",
       "  'contain',\n",
       "  'hidden',\n",
       "  'layer',\n",
       "  'Deep',\n",
       "  'learning',\n",
       "  'part',\n",
       "  'broader'],\n",
       " ['DSC',\n",
       "  'SlideShare',\n",
       "  'Deep',\n",
       "  'Learning',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  'Artificial',\n",
       "  'Neural',\n",
       "  'Network'],\n",
       " ['Neural',\n",
       "  'networks',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'remainder',\n",
       "  'chapter',\n",
       "  'discusses',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'broader',\n",
       "  'less',\n",
       "  'detailed',\n",
       "  'perspective',\n",
       "  'briefly',\n",
       "  'survey',\n",
       "  'models',\n",
       "  'neural',\n",
       "  'networks'],\n",
       " ['Deep',\n",
       "  'Learning',\n",
       "  'Deep',\n",
       "  'Learning',\n",
       "  'new',\n",
       "  'area',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  'research',\n",
       "  'introduced',\n",
       "  'objective',\n",
       "  'moving',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  'closer'],\n",
       " ['Deep',\n",
       "  'Learning',\n",
       "  'Tutorials',\n",
       "  'DeepLearning',\n",
       "  'documentation',\n",
       "  'Deep',\n",
       "  'Learning',\n",
       "  'new',\n",
       "  'area',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  'research',\n",
       "  'introduced',\n",
       "  'objective',\n",
       "  'moving',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  'closer'],\n",
       " ['Deep',\n",
       "  'Learning',\n",
       "  'Udacity',\n",
       "  'Machine',\n",
       "  'learning',\n",
       "  'fastest',\n",
       "  'growing',\n",
       "  'exciting',\n",
       "  'fields',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'represents',\n",
       "  'true',\n",
       "  'bleeding',\n",
       "  'edge',\n",
       "  'course'],\n",
       " ['PanSci', 'intelligence'],\n",
       " ['Deep',\n",
       "  'Learning',\n",
       "  'NVIDIA',\n",
       "  'Developer',\n",
       "  'Deep',\n",
       "  'learning',\n",
       "  'fastest',\n",
       "  'growing',\n",
       "  'field',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'uses',\n",
       "  'many',\n",
       "  'layered',\n",
       "  'Deep',\n",
       "  'Neural',\n",
       "  'Networks',\n",
       "  'DNNs',\n",
       "  'learn',\n",
       "  'levels',\n",
       "  'representation'],\n",
       " ['Deep',\n",
       "  'Learning',\n",
       "  'MIT',\n",
       "  'Technology',\n",
       "  'Review',\n",
       "  'massive',\n",
       "  'amounts',\n",
       "  'computational',\n",
       "  'power',\n",
       "  'machines',\n",
       "  'recognize',\n",
       "  'objects',\n",
       "  'translate',\n",
       "  'speech',\n",
       "  'real',\n",
       "  'time',\n",
       "  'Artificial',\n",
       "  'intelligence',\n",
       "  'finally',\n",
       "  'getting']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.lowercase = False\n",
    "tc.lemmatize = False\n",
    "tc.clean(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
